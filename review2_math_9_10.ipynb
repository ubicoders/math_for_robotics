{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Eigenvalues and Eigenvectors\n",
    "\n",
    "# Eigenvectors and Eigenvalues\n",
    "\n",
    "Eigenvectors and eigenvalues are fundamental concepts in linear algebra with applications in various fields like mathematics, physics, and engineering. Here's an explanation:\n",
    "\n",
    "---\n",
    "\n",
    "## **What are Eigenvectors and Eigenvalues?**\n",
    "\n",
    "1. **Eigenvectors:**\n",
    "   An eigenvector of a square matrix \\( A \\) is a non-zero vector \\( \\mathbf{v} \\) such that when \\( A \\) acts on \\( \\mathbf{v} \\), the output is a scaled version of \\( \\mathbf{v} \\). Mathematically:\n",
    "\n",
    "   $$\n",
    "   A\\mathbf{v} = \\lambda \\mathbf{v}\n",
    "   $$\n",
    "\n",
    "   - $ \\mathbf{v} $: The eigenvector.\n",
    "   - $ \\lambda $: The eigenvalue (a scalar).\n",
    "\n",
    "   In simple terms, an eigenvector is a direction in the space that remains unchanged in direction under the transformation described by the matrix A.\n",
    "\n",
    "2. **Eigenvalues:**\n",
    "   The eigenvalue $ \\lambda $ represents the scaling factor by which the eigenvector is stretched or compressed during the transformation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Intuition**\n",
    "- Imagine a matrix  A  as a transformation (e.g., rotation, stretching, or shearing) of vectors in space.\n",
    "- Most vectors will change both direction and magnitude under this transformation.\n",
    "- However, eigenvectors are special because they only change in magnitude (scaled by the eigenvalue $\\ \\lambda$ , not in direction.)\n",
    "\n",
    "---\n",
    "\n",
    "## **Example**\n",
    "Suppose A  is a 2x2 matrix representing a transformation in a 2D plane:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Let $ \\mathbf{v} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $. Applying A to $ \\mathbf{v} $:\n",
    "\n",
    "$$\n",
    "A \\mathbf{v} = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The resulting vector $ \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix} $ is 3 times $ \\mathbf{v}$. Thus:\n",
    "- $ \\mathbf{v} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $ is an eigenvector.\n",
    "- $ \\lambda = 3 $ is the eigenvalue.\n",
    "\n",
    "---\n",
    "\n",
    "## **How to Find Eigenvectors and Eigenvalues**\n",
    "\n",
    "1. Start with the equation:\n",
    "\n",
    "   $$\n",
    "   A\\mathbf{v} = \\lambda \\mathbf{v}\n",
    "   $$\n",
    "\n",
    "   Rearrange to:\n",
    "\n",
    "   $$\n",
    "   (A - \\lambda I)\\mathbf{v} = 0\n",
    "   $$\n",
    "\n",
    "   - $ I $: Identity matrix.\n",
    "   - $ \\lambda I $: Scales the eigenvector.\n",
    "\n",
    "2. For a non-zero $ \\mathbf{v} $, the determinant of $(A - \\lambda I) $ must be 0:\n",
    "\n",
    "   $$\n",
    "   \\det(A - \\lambda I) = 0\n",
    "   $$\n",
    "\n",
    "   This is called the **characteristic equation** and solving it gives the eigenvalues $ \\lambda $.\n",
    "\n",
    "3. Substitute each $ \\lambda $ back into $ (A - \\lambda I)\\mathbf{v} = 0 $ to find the corresponding eigenvectors $ \\mathbf{v} $.\n",
    "\n",
    "---\n",
    "\n",
    "## **Applications**\n",
    "- **Data science:** Principal Component Analysis (PCA) uses eigenvectors and eigenvalues for dimensionality reduction.\n",
    "- **Physics:** Analyzing the natural frequencies of systems.\n",
    "- **Robotics:** State estimation in Kalman filters.\n",
    "- **Computer graphics:** Transformations of 3D objects.\n",
    "- **Differential equations:** Solutions to linear systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Compute Eigenvalues and Eigenvectors\n",
    "\n",
    "- We define a symmetric covariance matrix and compute its eigenvalues and eigenvectors using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a symmetric covariance matrix\n",
    "cov_matrix = np.array([\n",
    "    [2.0, 0.8, 0.4],\n",
    "    [0.8, 1.5, 0.3],\n",
    "    [0.4, 0.3, 1.0]\n",
    "])\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Print results\n",
    "print(\"Covariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Interpretation\n",
    "\n",
    "- The eigenvalues represent the variance along the corresponding eigenvectors.\n",
    "- Eigenvectors define the principal directions of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Singular Value Decomposition (SVD)\n",
    "\n",
    "Singular Value Decomposition (SVD) is a matrix factorization technique widely used in data science, machine learning, and signal processing for tasks like dimensionality reduction and matrix approximations.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### SVD Formula\n",
    "- For a matrix $A$ of size $m \\times n$:\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "- $U$: Orthogonal matrix of size $m \\times m$ (left singular vectors).\n",
    "- $\\Sigma$: Diagonal matrix of singular values (size $m \\times n$).\n",
    "- $V^T$: Orthogonal matrix of size $n \\times n$ (right singular vectors).\n",
    "\n",
    "### Applications\n",
    "- Dimensionality reduction.\n",
    "- Image compression.\n",
    "- Principal Component Analysis (PCA).\n",
    "\n",
    "---\n",
    "In this chapter, we:\n",
    "1. Perform SVD on a random dataset.\n",
    "2. Compare eigenvalues with singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random dataset\n",
    "np.random.seed(42)  # For reproducibility\n",
    "data = np.random.rand(5, 3)  # 5 samples, 3 features\n",
    "\n",
    "# Compute the covariance matrix\n",
    "mean_centered_data = data - np.mean(data, axis=0)\n",
    "cov_matrix = np.cov(mean_centered_data, rowvar=False)\n",
    "\n",
    "# Perform Singular Value Decomposition\n",
    "U, S, VT = np.linalg.svd(cov_matrix)\n",
    "\n",
    "# eigen vectors and values\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Covariance Matrix:\\n\", cov_matrix)\n",
    "\n",
    "print(\"\\nEigenvalues (EVD):\\n\", eigenvalues)\n",
    "print(\"\\nEigenvectors (EVD):\\n\", eigenvectors)\n",
    "\n",
    "print(\"\\nSingular Values (SVD):\\n\", S)\n",
    "print(\"\\nLeft Singular Vectors (U):\\n\", U)\n",
    "print(\"\\nRight Singular Vectors (V^T):\\n\", VT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
